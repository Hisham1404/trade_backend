<context>
# Overview
The Trading Intelligence Agent is an AI-powered system that continuously monitors diverse Indian financial news sources, regulatory publications (SEBI, RBI, NSE/BSE circulars), government policy updates and market data to predict movements in the Indian equity and derivatives markets—particularly index and stock options. Unlike mainstream trading bots that rely on technical analysis alone, this agent focuses on fundamental and sentiment-driven analysis through real-time information gathering, providing users with early warnings and strategy suggestions (directional or market-neutral) tailored to the National Stock Exchange (NSE) and Bombay Stock Exchange (BSE).

# Core Features

## 1. Multi-Source News Aggregation
- **What it does**: Continuously scrapes and monitors Indian business media (Economic Times, Moneycontrol, LiveMint), exchange circulars (NSE, BSE), regulatory bodies (SEBI, RBI, MoF), corporate filings, and influential social-media handles focused on Indian markets
- **Why it's important**: Early access to market-moving information provides a competitive edge in trading decisions
- **How it works**: Dual monitoring approach:
  - **High-Priority Sources** (Exchange feeds, SEBI/RBI): Real-time monitoring via RSS/WebSocket
  - **General Sources** (News sites, social media): Batch scraping every 20-30 minutes
  - **Smart Caching**: Prevents duplicate processing, stores parsed content for 24 hours

## 2. AI-Powered Sentiment Analysis
- **What it does**: Analyzes gathered information to determine potential market impact on NSE/BSE listed equities and index futures/options
- **Why it's important**: Converts raw news data into actionable trading insights with directional bias indicators
- **How it works**: Uses Google's Agent Development Kit (ADK) with LLMs to understand context, sentiment, and potential market implications
- **Trading Signal Logic**:
  - **News Classification**: Corporate results, regulatory changes, macro policy, market rumors
  - **Impact Assessment**: Magnitude (1-10) × Source Reliability × News Type Weight
  - **Signal Generation**: 
    - Strong Bullish (>8): Major positive catalysts with high reliability
    - Bullish (6-8): Positive developments or sentiment shifts
    - Neutral (4-6): Mixed signals or low-impact news
    - Bearish (2-4): Negative developments or concerns
    - Strong Bearish (<2): Major negative catalysts with high reliability
  - **Risk Disclaimer**: All signals are informational only, not financial advice

## 3. Real-Time Alert System
- **What it does**: Sends immediate notifications when significant market-moving events are detected
- **Why it's important**: Allows users to react quickly to market changes before the broader market responds
- **How it works**: Push notifications through the API with detailed analysis and source citations

## 4. Intelligent Source Discovery
- **What it does**: Automatically discovers and saves new reliable information sources related to user's portfolio
- **Why it's important**: Expands the information network over time, improving prediction accuracy
- **How it works**: When a stock or index is added to tracking, the agent searches for relevant sources and validates their reliability and persistently stores vetted links in the `Source` table for reuse in future scraping cycles
- **Reliability Scoring**: Sources are scored on a 1-10 scale based on:
  - **Authority** (8-10): Official exchanges, SEBI, RBI, company filings
  - **Verified Media** (6-8): Established financial news outlets with editorial standards
  - **Social Signals** (3-6): Verified social accounts, popular finance influencers
  - **Unverified** (1-3): Anonymous sources, new accounts, uncorroborated claims

## 5. Option Chain & Open Interest Analytics
- **What it does**: Fetches live option chain data (strike-wise OI, volume, IV) for tracked symbols; identifies unusual activity, max pain, PCR, and potential breakout zones
- **How it works**: Integrates with NSE/BSE data endpoints or authorised market-data vendors; runs analytics every 5 minutes during market hours; stores snapshots for trend analysis

## 6. Participant Flow Tracking
- **What it does**: Monitors daily derivatives statistics of FIIs, DIIs, proprietary desks, and retail to gauge bullish/bearish bias
- **How it works**: Ingests cash & derivatives statistics published by NSE; aggregates into rolling metrics

## 7. Position Sizing & Leverage Guidelines
- **What it does**: Provides suggested lot sizes and leverage usage based on user risk profile and SPAN margin requirements
- **How it works**: Uses margin APIs (e.g., from Zerodha/Kite or Upstox) and SEBI's peak margin rules to compute available exposure

# User Experience

## User Personas
- **Active Options Traders**: Need real-time alerts on OI changes, IV spikes, and news-driven opportunities
- **Swing Traders**: Want to monitor regulatory changes, earnings announcements, and sector rotations
- **Institutional Desk Traders**: Require participant flow analysis and large block deal notifications

## Key User Flows
1. **Initial Setup**: User adds stocks/indices to portfolio → Agent discovers relevant sources → Begin monitoring
2. **Daily Usage**: Receive push notifications → Review detailed analysis → Make trading decisions
3. **Portfolio Management**: Add/remove assets → Agent adjusts monitoring scope → Updates source list

## UI/UX Considerations
- RESTful API design for frontend flexibility
- Real-time WebSocket connections for live updates
- Structured JSON responses with confidence scores
- Rate limiting to prevent API abuse
</context>
<PRD>
# Technical Architecture

## System Components

### 1. FastAPI Backend
- **Core API Server**: Handles all client requests, authentication, and response formatting
- **WebSocket Server**: Manages real-time connections for live alerts
- **Background Task Manager**: Coordinates scheduled scraping and analysis jobs

### 2. Google Agent Development Kit (ADK) Integration
- **Sequential Processing Pipeline**: News gathering → Analysis → Alert generation
- **Parallel Processing**: Multiple sources scraped simultaneously for efficiency
- **Agent Orchestration**: Manages different specialized agents (news, regulatory, social media)

### 3. Data Collection Layer
- **Web Scrapers**: BeautifulSoup/Scrapy for HTML parsing
- **API Integrators**: NSE/BSE option chain, margin, and market-depth APIs; reputable data vendors (e.g., Zerodha, TrueData)
- **RSS/Feed Parsers**: Business news feeds (Economic Times, Moneycontrol)
- **Government/Regulatory Crawlers**: SEBI circulars, RBI releases, MoF press notes
- **Sentiment Sources**: Indian finance Twitter handles, StockTwits India, YouTube transcripts

### 4. Analysis Engine
- **NLP Processing**: Sentiment analysis and entity extraction
- **Market Impact Scorer**: Rates news importance (1-10 scale)
- **Correlation Engine**: Links news to specific stocks/indices and their derivatives

### 5. Storage Layer
- **PostgreSQL**: Main database for user data, portfolios, and historical alerts
- **Redis**: Cache for frequently accessed data and rate limiting
- **Vector Database**: For storing news embeddings and similarity search

## Data Models

```python
# Core Models
User
- id, email, api_key, subscription_tier
- created_at, last_active

Portfolio
- id, user_id, name
- assets: [Asset]
- alert_preferences

Asset
- id, symbol, segment (equity/index), derivative_type (call/put/futures/null)
- monitoring_sources: [Source]
- alert_threshold
- sentiment_snapshot

NewsItem
- id, source_id, title, content, url
- published_at, scraped_at
- sentiment_score, impact_score
- related_assets: [Asset]

Alert
- id, user_id, asset_id, news_item_id
- type (buy/sell/warning)
- confidence_score, reason
- created_at, acknowledged_at

Source
- id, url, type, reliability_score
- last_checked, check_frequency
- auth_required, credentials
- **auto_discovered: bool**
```

## APIs and Integrations

### External APIs
- NSE/BSE official data & circular feeds
- SEBI/RBI/Ministry of Finance sites
- Market-data vendor APIs (Zerodha Kite Connect, Upstox API, FYERS Data)

### Internal API Endpoints
```
POST /api/v1/portfolio/assets - Add asset to monitor
DELETE /api/v1/portfolio/assets/{id} - Remove asset
GET /api/v1/alerts - Get recent alerts
GET /api/v1/alerts/live - WebSocket for real-time alerts
POST /api/v1/sources/discover - Trigger source discovery
GET /api/v1/analysis/{asset_id} - Get detailed analysis
```

## Infrastructure Requirements
- **Compute**: Scalable containers for parallel processing
- **Storage**: 100GB+ for historical data and caching
- **Network**: High bandwidth for continuous scraping
- **Security**: SSL/TLS, API key authentication, rate limiting

# Development Roadmap

## Phase 1: MVP Foundation
- Basic FastAPI server with authentication
- Core data models and PostgreSQL setup
- Simple news scraper for 3-5 major sources
- Basic sentiment analysis using pre-trained models
- REST API for portfolio management
- Manual source addition capability

## Phase 2: Intelligence Layer
- Google ADK integration for advanced analysis
- Parallel processing for multiple sources
- Smart source discovery algorithm
- Confidence scoring for predictions
- Historical correlation tracking

## Phase 3: Real-time Capabilities
- WebSocket implementation for live alerts
- Redis caching layer
- Background job scheduling (Celery)
- Rate limiting and API optimization
- Push notification system

## Phase 4: Advanced Features
- Government site specialized crawlers
- Investment portfolio tracking
- Multi-language support for global sources
- Machine learning for pattern recognition
- Custom alert rules and filters

## Phase 5: Scale & Optimize
- Distributed scraping infrastructure
- Advanced caching strategies
- API versioning and backwards compatibility
- Performance monitoring and alerting
- User analytics and insights

# Logical Dependency Chain

1. **Foundation Setup** (Must be first)
   - FastAPI server structure
   - Database schema and models
   - Basic authentication system

2. **Data Collection Pipeline** (Depends on Foundation)
   - Web scraping framework
   - Source management system 
   - Data validation and cleaning

3. **Analysis Engine** (Depends on Data Collection)
   - Google ADK integration
   - Sentiment analysis implementation
   - Asset correlation logic

4. **User Interface Layer** (Can parallel with Analysis)
   - REST API endpoints
   - Response formatting
   - Error handling

5. **Real-time Features** (Depends on all above)
   - WebSocket server
   - Alert generation system
   - Push notifications

6. **Intelligence Enhancement** (Iterative improvements)
   - Source discovery
   - Pattern learning
   - Prediction accuracy

# Risks and Mitigations

## Technical Challenges
- **Risk**: Rate limiting and IP blocking from scraped sites
- **Mitigation**: Implement rotating proxies, respect robots.txt, add delays

- **Risk**: False positive alerts causing poor trades
- **Mitigation**: Confidence scoring, user verification options, historical accuracy tracking

- **Risk**: Google ADK API costs at scale
- **Mitigation**: Implement caching, batch processing, tiered user plans

## Market-Specific Risks
- **Risk**: Social media manipulation (pump & dump schemes, coordinated misinformation)
- **Mitigation**: Cross-reference multiple sources, prioritize official channels, implement anomaly detection for sudden sentiment spikes

- **Risk**: High costs of real-time market data from NSE/BSE authorized vendors
- **Mitigation**: Start with delayed data for MVP, negotiate bulk pricing, pass costs to premium tiers, use broker APIs where possible

## Scalability Concerns
- **Risk**: Database performance with millions of news items
- **Mitigation**: Implement data archival, use time-series databases, optimize queries

- **Risk**: Real-time processing bottlenecks
- **Mitigation**: Horizontal scaling, queue-based architecture, load balancing

## Legal and Compliance
- **Risk**: Web scraping legal issues
- **Mitigation**: Terms of service compliance, official API usage where available

- **Risk**: Financial advice regulations
- **Mitigation**: Clear disclaimers, "information only" positioning, no guaranteed returns

# Appendix

## Technology Stack
- **Backend**: FastAPI, Python 3.11+
- **AI/ML**: Google ADK, Transformers, spaCy
- **Database**: PostgreSQL, Redis, Pinecone
- **Scraping**: BeautifulSoup, Scrapy, Playwright
- **Infrastructure**: Docker, Kubernetes, Cloud Run
- **Monitoring**: Prometheus, Grafana, Sentry

## Source Categories
1. **Mainstream News**: Economic Times, Moneycontrol, LiveMint
2. **Regulatory**: SEBI circulars, NSE/BSE announcements, RBI policy updates
3. **Market Data**: Option chain, OI statistics, participant activity reports
4. **Social Signals**: Finance Twitter (FinTwit India), StockTwits India, Telegram channels (curated & vetted)

## Performance Targets
- High-priority source monitoring: Real-time (sub-second for exchange feeds)
- General news scan frequency: Every 20-30 minutes
- Alert latency: < 2 minutes from publication (for monitored real-time sources)
- Alert latency: < 30 minutes from publication (for batch-scraped sources)
- API response time: < 200ms for queries
- Option chain refresh: Every 5 minutes during market hours
- Uptime: 99.9% availability
- Concurrent users: 10,000+ supported
</PRD> 